{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 表格结构识别流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础环境\n",
    "import os\n",
    "import sys\n",
    "import fire\n",
    "import shutil\n",
    "import comet_ml\n",
    "from tqdm import tqdm\n",
    "from icecream import ic\n",
    "from datetime import datetime\n",
    "from pathlib import PurePath, Path\n",
    "\n",
    "# FILE = Path(__file__).resolve()\n",
    "FILE = Path(\"/home/aor/projects/Developing/eldsich/pdf_parser\").resolve()\n",
    "ROOT = str(FILE.parents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aor/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/aor/.conda/envs/pdf_parser/lib/python3.10/site-packages/transformers/models/detr/feature_extraction_detr.py:38: FutureWarning: The class DetrFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DetrImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 初始化结构识别工具\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import AutoImageProcessor\n",
    "from transformers import DetrFeatureExtractor\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "structure_model = TableTransformerForObjectDetection.from_pretrained(\"../weights/table_transformer/table-transformer-structure-recognition-v1.1-all\")\n",
    "feature_extractor = DetrFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常量数据和辅助函数\n",
    "label_types = [\n",
    "    \"Bracket_Need_Type1\",\n",
    "    \"Bracket_Need_Type2\",\n",
    "    \"Bracket_Need_Type3\",\n",
    "    \"Bracket_Abort_Type1\",\n",
    "    \"Bracket_Abort_Type2\",\n",
    "    \"Pipe_Need_Type1\",\n",
    "    \"Pipe_Abort_Type1\"\n",
    "]\n",
    "\n",
    "required_labels = [\n",
    "    \"Bracket_Need_Type1\",\n",
    "    \"Bracket_Need_Type2\",\n",
    "    \"Bracket_Need_Type3\",\n",
    "    \"Pipe_Need_Type1\",\n",
    "]\n",
    "\n",
    "# 识别图片文件后缀\n",
    "def get_file_extension_in_dir(dir_path: str, file_name: str):\n",
    "    for file in os.listdir(dir_path):\n",
    "        name, extension = os.path.splitext(file)\n",
    "        if name == file_name:\n",
    "            return extension\n",
    "    return None\n",
    "\n",
    "# 读取detect标记数据\n",
    "def get_labeled_data(label_path : str):\n",
    "    data = pd.read_csv(label_path, header=None, sep=\" \", names=[\"label_id\", \"x\", \"y\", \"w\", \"h\", \"conf\"])\n",
    "    return data\n",
    "\n",
    "# 截取识别的图片\n",
    "def get_crops(dir : str):\n",
    "    # 删除原有的文件夹\n",
    "    crop_dir = os.path.join(dir, \"crops\")\n",
    "    if os.path.exists(crop_dir):\n",
    "        shutil.rmtree(crop_dir)\n",
    "    os.makedirs(crop_dir)\n",
    "\n",
    "    # 读取图片数据\n",
    "    img_ext = get_file_extension_in_dir(os.path.join(dir, \"detect\"), \"origin\")\n",
    "    img_path = os.path.join(dir, f\"detect/origin{img_ext}\")\n",
    "    img = Image.open(img_path)\n",
    "    img_w, img_y = img.size\n",
    "\n",
    "    # 读取标记数据\n",
    "    label_path = os.path.join(dir, \"detect/labels.txt\")\n",
    "    label_data = get_labeled_data(label_path)\n",
    "\n",
    "    # 遍历识别子图\n",
    "    for idx, row in label_data.iterrows():\n",
    "        label_id, x, y, w, h = row[\"label_id\"], row[\"x\"], row[\"y\"], row[\"w\"], row[\"h\"]\n",
    "        label_name = label_types[int(label_id)]\n",
    "\n",
    "        # 跳过不需要的标记\n",
    "        if label_name not in required_labels:\n",
    "            continue\n",
    "\n",
    "        # 截图\n",
    "        crop = img.crop(((x - 0.5 * w) * img_w,\n",
    "                         (y - 0.5 * h) * img_y,\n",
    "                         (x + 0.5 * w) * img_w,\n",
    "                         (y + 0.5 * h) * img_y))\n",
    "        crop.save(os.path.join(crop_dir, f\"{label_name}-{idx}.{img_ext}\"))\n",
    "\n",
    "# 对截取图片进行结构识别\n",
    "def structure_recognition(dir : str):    \n",
    "    # 重建recognize文件夹\n",
    "    recognize_dir = os.path.join(dir, \"recognize\")\n",
    "    if os.path.exists(recognize_dir):\n",
    "        shutil.rmtree(recognize_dir)\n",
    "    os.makedirs(recognize_dir)\n",
    "\n",
    "    # 读取图片数据\n",
    "    crop_dir = os.path.join(dir, \"crops\")\n",
    "    crop_files = os.listdir(crop_dir)\n",
    "    crop_names = [file.split(\".\")[0] for file in crop_files]\n",
    "    crops = [Image.open(os.path.join(crop_dir, file)).convert(\"RGB\") for file in crop_files]\n",
    "\n",
    "    for crop_idx in range(len(crops)):\n",
    "        crop_name = crop_names[crop_idx]\n",
    "        crop_img = crops[crop_idx]\n",
    "\n",
    "        # 创建识别结果目录\n",
    "        crop_recognize_dir = os.path.join(recognize_dir, crop_name)\n",
    "        os.makedirs(crop_recognize_dir)\n",
    "\n",
    "        # 执行结构识别\n",
    "        encoding = feature_extractor(images=crop_img, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = structure_model(**encoding)\n",
    "        target_sizes = [crop_img.size[::-1]]\n",
    "        results = feature_extractor.post_process_object_detection(outputs,\n",
    "                                                                  threshold = 0.5,\n",
    "                                                                  target_sizes=target_sizes)[0]\n",
    "        \n",
    "        # 调整结果格式\n",
    "        recognized = {}\n",
    "        recognized[\"scores\"] = results[\"scores\"].tolist()\n",
    "        recognized[\"labels\"] = results[\"labels\"].tolist()\n",
    "\n",
    "        boxes = results[\"boxes\"].tolist()\n",
    "        recognized[\"box0\"] = [box[0] for box in boxes]\n",
    "        recognized[\"box1\"] = [box[1] for box in boxes]\n",
    "        recognized[\"box2\"] = [box[2] for box in boxes]\n",
    "        recognized[\"box3\"] = [box[3] for box in boxes]\n",
    "\n",
    "        # 保存结果\n",
    "        recognized_df = pd.DataFrame(recognized)\n",
    "        recognized_df.to_csv(os.path.join(crop_recognize_dir, \"recognized.csv\"), index=False)\n",
    "\n",
    "        # 绘制并保存识别结果\n",
    "        mark_img = crop_img.copy()\n",
    "        draw = ImageDraw.Draw(mark_img)\n",
    "        for i in range(len(results[\"boxes\"])):\n",
    "            box = [int(_) for _ in results[\"boxes\"][i].tolist()]\n",
    "            draw.rectangle(box, outline=\"red\", width=2)\n",
    "        mark_img.save(os.path.join(crop_recognize_dir, \"marked.jpg\"))\n",
    "        crop_img.save(os.path.join(crop_recognize_dir, \"origin.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(dir : str):\n",
    "    page_names = os.listdir(dir)\n",
    "    for page_name in tqdm(page_names):\n",
    "        ic(page_name)\n",
    "        page_dir = os.path.join(dir, page_name)\n",
    "        get_crops(page_dir)\n",
    "        structure_recognition(page_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?it/s]ic| page_name: '3'\n",
      "  3%|▎         | 1/31 [00:00<00:16,  1.86it/s]ic| page_name: '30'\n",
      "  6%|▋         | 2/31 [00:00<00:13,  2.21it/s]ic| page_name: '4'\n",
      " 10%|▉         | 3/31 [00:01<00:11,  2.35it/s]ic| page_name: '7'\n",
      " 13%|█▎        | 4/31 [00:01<00:11,  2.45it/s]ic| page_name: '18'\n",
      " 16%|█▌        | 5/31 [00:02<00:10,  2.48it/s]ic| page_name: '14'\n",
      " 19%|█▉        | 6/31 [00:02<00:10,  2.41it/s]ic| page_name: '15'\n",
      " 23%|██▎       | 7/31 [00:03<00:10,  2.28it/s]ic| page_name: '9'\n",
      " 26%|██▌       | 8/31 [00:03<00:10,  2.19it/s]ic| page_name: '2'\n",
      " 29%|██▉       | 9/31 [00:03<00:09,  2.29it/s]ic| page_name: '20'\n",
      " 32%|███▏      | 10/31 [00:04<00:07,  2.77it/s]ic| page_name: '6'\n",
      " 35%|███▌      | 11/31 [00:04<00:06,  3.22it/s]ic| page_name: '10'\n",
      " 39%|███▊      | 12/31 [00:04<00:07,  2.67it/s]ic| page_name: '8'\n",
      " 42%|████▏     | 13/31 [00:05<00:06,  2.89it/s]ic| page_name: '16'\n",
      " 45%|████▌     | 14/31 [00:05<00:05,  2.90it/s]ic| page_name: '26'\n",
      " 48%|████▊     | 15/31 [00:05<00:05,  2.93it/s]ic| page_name: '28'\n",
      " 52%|█████▏    | 16/31 [00:06<00:04,  3.12it/s]ic| page_name: '27'\n",
      " 55%|█████▍    | 17/31 [00:06<00:04,  3.47it/s]ic| page_name: '24'\n",
      " 58%|█████▊    | 18/31 [00:06<00:03,  3.89it/s]ic| page_name: '13'\n",
      " 61%|██████▏   | 19/31 [00:06<00:04,  2.96it/s]ic| page_name: '17'\n",
      " 65%|██████▍   | 20/31 [00:07<00:04,  2.61it/s]ic| page_name: '11'\n",
      " 68%|██████▊   | 21/31 [00:07<00:03,  2.67it/s]ic| page_name: '23'\n",
      " 71%|███████   | 22/31 [00:08<00:03,  2.51it/s]ic| page_name: '12'\n",
      " 74%|███████▍  | 23/31 [00:08<00:03,  2.54it/s]ic| page_name: '0'\n",
      " 77%|███████▋  | 24/31 [00:08<00:02,  2.86it/s]ic| page_name: '5'\n",
      " 81%|████████  | 25/31 [00:09<00:02,  2.67it/s]ic| page_name: '22'\n",
      " 84%|████████▍ | 26/31 [00:09<00:01,  2.63it/s]ic| page_name: '1'\n",
      " 87%|████████▋ | 27/31 [00:10<00:01,  2.70it/s]ic| page_name: '29'\n",
      " 90%|█████████ | 28/31 [00:10<00:01,  2.63it/s]ic| page_name: '21'\n",
      " 94%|█████████▎| 29/31 [00:10<00:00,  2.59it/s]ic| page_name: '19'\n",
      " 97%|█████████▋| 30/31 [00:11<00:00,  2.70it/s]ic| page_name: '25'\n",
      "100%|██████████| 31/31 [00:11<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "recognize(\"./results_2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
